{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3468bf-dc8b-4e73-a721-519d359ea7ca",
   "metadata": {},
   "source": [
    " # <b>1 <span style='color:#F76241'>|</span>Some good ol' fashion data munging</b>\n",
    " \n",
    "<font size=\"9\">A</font>lright!. It's time to start preparing the data for machine learning algorithms. No matter the machine learning system, there is _always_ a need to perform some kind of preprocessing. In our case, for the housing dataset,\n",
    "we are going to:\n",
    "\n",
    "- Scale the data so every number lies in the same range\n",
    "- Adding missing values\n",
    "- Transform the categorical columns to be numerical\n",
    "\n",
    "First, lets retrieve the relevant code from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b74f6f-9ed7-475b-9b20-469bbbcb3b50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv(\"data/housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7aa54f-13d8-4ad3-ab18-79fa654c42c8",
   "metadata": {},
   "source": [
    "Now we need to deal with missing values. If you recall, in the **housing** dataset, the **total_bedrooms** columns has missing values. There are several ways to approach this such as:\n",
    "\n",
    "1. Get rid of the rows with missing values for **total_bedrooms**.\n",
    "2. Get rid of the whole attribute.\n",
    "3. Set the missing values to some value (zero, the mean, the median, etc.). This is called imputation.\n",
    "\n",
    "Option 3 is the most recommended. For this showcase however, I'm going to keep things simple and just drop the records with missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8e0ddc-74a7-4c05-b8d6-618228ff29da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3573c79-e4bf-4d38-81c0-de4839a37f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca93265-8db2-4d8c-815d-48c05b1d1e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16346, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17727</th>\n",
       "      <td>-121.80</td>\n",
       "      <td>37.32</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>2698.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>4.7027</td>\n",
       "      <td>227600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>-119.63</td>\n",
       "      <td>36.64</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.4107</td>\n",
       "      <td>110400.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6453</th>\n",
       "      <td>-118.06</td>\n",
       "      <td>34.12</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3891.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>3.6639</td>\n",
       "      <td>248100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>-118.31</td>\n",
       "      <td>34.07</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2362.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2759.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>2.2364</td>\n",
       "      <td>305600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15266</th>\n",
       "      <td>-117.27</td>\n",
       "      <td>33.04</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1839.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>3.5500</td>\n",
       "      <td>214600.0</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms   \n",
       "17727    -121.80     37.32                14.0       4412.0           924.0  \\\n",
       "2057     -119.63     36.64                33.0       1036.0           181.0   \n",
       "6453     -118.06     34.12                25.0       3891.0           848.0   \n",
       "4619     -118.31     34.07                28.0       2362.0           949.0   \n",
       "15266    -117.27     33.04                27.0       1839.0           392.0   \n",
       "\n",
       "       population  households  median_income  median_house_value   \n",
       "17727      2698.0       891.0         4.7027            227600.0  \\\n",
       "2057        620.0       174.0         3.4107            110400.0   \n",
       "6453       1848.0       759.0         3.6639            248100.0   \n",
       "4619       2759.0       894.0         2.2364            305600.0   \n",
       "15266      1302.0       404.0         3.5500            214600.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "17727       <1H OCEAN  \n",
       "2057           INLAND  \n",
       "6453           INLAND  \n",
       "4619        <1H OCEAN  \n",
       "15266      NEAR OCEAN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d8141-aa17-438d-8dba-35273095161f",
   "metadata": {},
   "source": [
    "Next, we need to extract the **y values** from the training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "239e1bc5-951b-459e-977f-b20a48c56b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop([\"median_house_value\"],axis=1)\n",
    "y_train = df_train['median_house_value']\n",
    "\n",
    "X_test = df_test.drop([\"median_house_value\"],axis=1)\n",
    "y_test = df_test[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15ec3588-9862-488f-993d-c2510df161fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16346, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c249741e-1449-422c-a6ba-1ff9087d5edd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16346,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e7dabf-e786-46e0-93b8-5895aef4a2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4087, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f64a096-b181-46f3-8858-69af6596e62c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4087,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3824dca5-9709-4b3f-b70f-834f396ed960",
   "metadata": {},
   "source": [
    "When it comes to text columns, there's numerous approaches as well. For this example, we're just going to exclude them. But realistically, they should be converted into numericals and used for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8077b713-c2ab-4f28-aafb-0b5f5ccd22ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=[\"ocean_proximity\"])\n",
    "X_test = X_test.drop(columns=[\"ocean_proximity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4a590-b0a8-4bbd-8799-43be81543877",
   "metadata": {},
   "source": [
    "The last preprocessing step we'll perform is feature scaling. This is done to make sure that each numerical value is within the same range. Values of varying ranges tend to trip up machine learning algorithms. We will use sklearn's **StandardScaler** class to do this.\n",
    "\n",
    "It's important to fit the model to the training data, and then **only** transform the test data, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d3a3f1-dfc8-4c0f-8680-71bf4b181255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934294c-a6f8-4ae9-a707-c49972930a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
